{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстовых комментариев на позитивные и негативные\n",
    "\n",
    "\n",
    "## Данные\n",
    "\n",
    "В наличии один датасет со столбцами *text*, в котором содержатся текст комментария и  *toxic* — целевой признак (токсичный или не токсичный даный комментарий).\n",
    "\n",
    "## Задача\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "## Используемые библиотеки\n",
    "*pandas, sklearn, catboost, nltk, transformers, torch, tqdm, hyperopt*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Заблокируем предупреждения\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import notebook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на основную информацию из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corpus.shape)\n",
    "print(corpus.info())\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак мы видим, датасет состоящий из 159571 строки и 2 столбцов. Один столбец представлен в виде строк (object). Второй столбец представлен целыми числами - 0 и 1. Можно выделить следующие особенности даноого датасета:\n",
    "* Пропусков нет\n",
    "* Дубликатов нет\n",
    "* Имеется дисбаланс классов - Позитивных - 10.2%, негативных - 89.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Лемматизация и очистка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим корпус на обучающую, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(corpus, test_size=0.2, random_state=12345)\n",
    "data_train = data_train.reset_index(drop=True)\n",
    "data_test = data_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку для поиска оптимальных параметров моделей я использую подхjды на основе кросс-валидации, валидационая выборка не нужна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = data_train[\"text\"]\n",
    "texts_test = data_test[\"text\"]\n",
    "texts_train = texts_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем дополнительные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Борис\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Борис\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для очистки и лемматизации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def texts_prepare(corpus):\n",
    "    texts_lemm = []\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    for sen in notebook.tqdm(range(0, len(corpus))):\n",
    "      # Удалим все специальные символы\n",
    "        document = re.sub(r'\\W', ' ', str(corpus[sen]))\n",
    "    \n",
    "    # Удалим все одиночные символы\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Удалим одиночные символы с самого начала\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Заменим несколько пробелов одним пробелом\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Удалим префикс \"b\"\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Переведем все буквы в нижний регистр\n",
    "        document = document.lower()\n",
    "    \n",
    "    # Проведем лемматизацию\n",
    "        document = document.split()\n",
    "\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "    \n",
    "        texts_lemm.append(document)\n",
    "    return texts_lemm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем очистку и лемматизацию текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc996aa16bb4558bad0ab9ea3c4a065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127656.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798a354ca97b4788bff4813747670c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31915.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts_train_lemm = texts_prepare(texts_train)\n",
    "texts_test_lemm = texts_prepare(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts_train_lemm.to_csv('texts_train_lemm', index = False)\n",
    "# texts_test_lemm.to_csv('texts_test_lemm', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts_train_lemm = pd.read_csv('tweets_lemm_train.csv')\n",
    "# texts_test_lemm = pd.read_csv('texts_test_lemm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем тестирование для определение лучших параметров векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222aa2c27caf488b8a462797a83600ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0eed2afc7974559a8456336a0dd1d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10dbb58c92e14b2790641ce3b7afbf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a2e2428ac24819a5a73251c0e8caed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09526f1d35e4ac6b69709e39bfee113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82410f47bbf47dda8ae99cef0940041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232cc678be7e44dbadc8c11065504d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6446f73bd5416bbf2a4ab209e1391c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23637e0937044e2e9822c520f1186087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51f7ab42ecc40928470f406380df518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6b159f30524faba916ae0766e60993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bc164135b141649b7271e4d7551c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2fc0f816514352b872e7ef269ccb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a3851e40c44473b8a46b1663d40683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9183e710304de1ba3511db513b8b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c68a87cf52437a82280a34cc4e0cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98c25174f4f4c4d9ed9f99990c4f188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_param = pd.DataFrame([])\n",
    "for max_features in notebook.tqdm(range(8000, 12000, 1000)):\n",
    "    for min_df in notebook.tqdm(range(5, 8, 1)):\n",
    "        for max_df in notebook.tqdm(np.arange(0.6, 0.9, 0.1)):\n",
    "            count_tf_idf = TfidfVectorizer(max_features=max_features, min_df=min_df, max_df=max_df, stop_words=stopwords)\n",
    "            tf_idf = count_tf_idf.fit_transform(texts_train_lemm)\n",
    "            tf_idf_test = count_tf_idf.transform(texts_test_lemm)\n",
    "            \n",
    "            target_train = data_train['toxic']\n",
    "            target_test = data_test['toxic']\n",
    "            features_train = tf_idf\n",
    "            features_test = tf_idf_test\n",
    "            \n",
    "            LR = LogisticRegression(random_state=12345, penalty = \"l1\")\n",
    "            LR.fit(features_train, target_train)\n",
    "            y_predict = LR.predict(features_test)\n",
    "                   \n",
    "            model_param = model_param.append(pd.DataFrame({\"max_features\": [max_features],\n",
    "                                                           \"min_df\": [min_df],\n",
    "                                                           \"max_df\": [max_df],\n",
    "                                                           \"f1_score\": [f1_score(target_test, y_predict)] \n",
    "                                               }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим лучшие параметры для векоризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.776192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.776192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.776192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.776192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.775922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  min_df  max_df  f1_score\n",
       "0         10000       5     0.6  0.776192\n",
       "0         10000       5     0.7  0.776192\n",
       "0         10000       5     0.9  0.776192\n",
       "0         10000       5     0.8  0.776192\n",
       "0         10000       7     0.8  0.775922"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param = model_param.sort_values(\"f1_score\", ascending = False)\n",
    "model_param.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем векторизацию текстов с данными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(max_features=10000, min_df=5, max_df=0.7, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = count_tf_idf.fit_transform(texts_train_lemm)\n",
    "tf_idf_test = count_tf_idf.transform(texts_test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей матрицы: (127656, 10000)\n",
      "Размер тестовой матрицы: (31915, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер обучающей матрицы:\", tf_idf.shape)\n",
    "print(\"Размер тестовой матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим выборки для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = data_train['toxic']\n",
    "target_test = data_test['toxic']\n",
    "\n",
    "features_train = tf_idf\n",
    "features_test = tf_idf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии на дефолтных параметрах и сделаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=12345, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=12345, penalty = \"l1\", max_iter = 100)\n",
    "LR.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на f1 тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score тест 0.776192133658197\n"
     ]
    }
   ],
   "source": [
    "y_predict_test = LR.predict(features_test)\n",
    "print(\"f1_score тест\", f1_score(target_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы добились необходимого результата, но попробуем его улучшить с помощью подбора параметров средствами библиотеки hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выполняется долго, поэтому я его закомментировал, а результат перенес в словарь best и в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 50/50 [19:41<00:00, 23.62s/trial, best loss: 0.12033248855872791]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import Trials\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin\n",
    "\n",
    "N_FOLDS = 10\n",
    "MAX_EVALS = 50\n",
    "\n",
    "\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Logistic Regression Hyperparameter Tuning\"\"\"\n",
    "\n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evaluate based on ROC AUC\n",
    "\n",
    "    clf = LogisticRegression(**params,random_state=0,verbose =0)\n",
    "    scores = cross_val_score(clf, features_train, target_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "    # Extract the best score\n",
    "    best_score = max(scores)\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, \"balanced\"]),\n",
    "    'penalty': hp.choice('penalty', [\"l1\", \"l2\"]),\n",
    "    'warm_start' : hp.choice('warm_start', [True, False]),\n",
    "    'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
    "    'C' : hp.uniform('C', 0.05, 3),\n",
    "    'max_iter' : hp.choice('max_iter', range(200,1000))\n",
    "}\n",
    "\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = bayes_trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.0587393315520224,\n",
       " 'class_weight': 0,\n",
       " 'max_iter': 248,\n",
       " 'penalty': 0,\n",
       " 'tol': 5.593994521218677e-05,\n",
       " 'warm_start': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с лучшими параметрами и получим предстказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score тест 0.7797131147540984\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=12345, C = 2.0587393315520224, penalty = \"l1\", max_iter = 248, tol = 5.593994521218677e-05, warm_start = False, class_weight = None)\n",
    "LR.fit(features_train, target_train)\n",
    "\n",
    "y_predict_test = LR.predict(features_test)\n",
    "\n",
    "print(\"f1_score тест\", f1_score(target_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель соответсвует необходимым требованиям, но попробуем ее еще улучшить через изменение порога классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.35 | Точность = 0.82, Полнота = 0.75, f1 = 0.7818\n",
      "Порог = 0.36 | Точность = 0.82, Полнота = 0.75, f1 = 0.7819\n",
      "Порог = 0.37 | Точность = 0.83, Полнота = 0.74, f1 = 0.7829\n",
      "Порог = 0.38 | Точность = 0.83, Полнота = 0.74, f1 = 0.7841\n",
      "Порог = 0.39 | Точность = 0.83, Полнота = 0.74, f1 = 0.7838\n",
      "Порог = 0.40 | Точность = 0.84, Полнота = 0.74, f1 = 0.7842\n",
      "Порог = 0.41 | Точность = 0.84, Полнота = 0.73, f1 = 0.7838\n",
      "Порог = 0.42 | Точность = 0.84, Полнота = 0.73, f1 = 0.7824\n",
      "Порог = 0.43 | Точность = 0.85, Полнота = 0.73, f1 = 0.7840\n",
      "Порог = 0.44 | Точность = 0.85, Полнота = 0.73, f1 = 0.7840\n",
      "Порог = 0.45 | Точность = 0.86, Полнота = 0.72, f1 = 0.7833\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, C = 2.0587393315520224, penalty = \"l1\", max_iter = 248, tol = 5.593994521218677e-05, warm_start = False, class_weight = None)\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.35, 0.45, 0.01):\n",
    "    predicted_test = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_test, predicted_test)\n",
    "    recall = recall_score(target_test, predicted_test)\n",
    "    f1 = f1_score(target_test, predicted_test)\n",
    "    print(\"Порог = {:.2f} | Точность = {:.2f}, Полнота = {:.2f}, f1 = {:.4f}\".format(threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший f1 = 0.784, достигается при пороге = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как покажет сябя стахостический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
       "              random_state=12345, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDC = SGDClassifier(loss = \"log\", penalty = \"l1\", random_state=12345, alpha=0.00001)\n",
    "SGDC.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score тест 0.7706582633053222\n"
     ]
    }
   ],
   "source": [
    "y_predict_test = SGDC.predict(features_test)\n",
    "\n",
    "print(\"f1_score тест\", f1_score(target_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем лучшие параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выполняется долго, поэтому я его закомментировал, а результат перенес в словарь best и в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 50/50 [15:52<00:00, 19.06s/trial, best loss: 0.12617593607183897]\n"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 10\n",
    "MAX_EVALS = 50\n",
    "\n",
    "\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Logistic Regression Hyperparameter Tuning\"\"\"\n",
    "\n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evaluate based on ROC AUC\n",
    "\n",
    "    clf = SGDClassifier(**params,random_state=12345, loss = \"log\", verbose = 0)\n",
    "    scores = cross_val_score(clf, features_train, target_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "    # Extract the best score\n",
    "    best_score = max(scores)\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, \"balanced\"]),\n",
    "    'penalty': hp.choice('penalty', [\"l1\", \"l2\"]),\n",
    "    'warm_start' : hp.choice('warm_start', [True, False]),\n",
    "    'fit_intercept' : hp.choice('fit_intercept', [True, False]),\n",
    "    'alpha' : hp.uniform('alpha', 0.0000001, 0.0001),\n",
    "    'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
    "    'max_iter' : hp.choice('max_iter', range(5, 1000))\n",
    "}\n",
    "\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = bayes_trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.2573330481208354e-05,\n",
       " 'class_weight': 0,\n",
       " 'fit_intercept': 1,\n",
       " 'max_iter': 679,\n",
       " 'penalty': 0,\n",
       " 'tol': 9.088054857563279e-05,\n",
       " 'warm_start': 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с лучшими параметрами и получим предстказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score тест 0.7770961145194274\n"
     ]
    }
   ],
   "source": [
    "SGDC = SGDClassifier(fit_intercept = True, alpha = 3.328059888505736e-06, loss = \"log\", random_state=12345, penalty = \"l1\", max_iter = 378, tol = 1.3032360763407112e-05, warm_start = True, class_weight = None)\n",
    "SGDC.fit(features_train, target_train)\n",
    "\n",
    "y_predict_test = SGDC.predict(features_test)\n",
    "\n",
    "print(\"f1_score тест\", f1_score(target_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель соответсвует необходимым требованиям, но попробуем ее еще улучшить через изменение порога классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.30 | Точность = 0.78, Полнота = 0.78, f1 = 0.7791\n",
      "Порог = 0.31 | Точность = 0.79, Полнота = 0.77, f1 = 0.7801\n",
      "Порог = 0.32 | Точность = 0.79, Полнота = 0.77, f1 = 0.7816\n",
      "Порог = 0.33 | Точность = 0.80, Полнота = 0.76, f1 = 0.7815\n",
      "Порог = 0.34 | Точность = 0.80, Полнота = 0.76, f1 = 0.7810\n",
      "Порог = 0.35 | Точность = 0.81, Полнота = 0.76, f1 = 0.7814\n",
      "Порог = 0.36 | Точность = 0.81, Полнота = 0.75, f1 = 0.7818\n",
      "Порог = 0.37 | Точность = 0.82, Полнота = 0.75, f1 = 0.7831\n",
      "Порог = 0.38 | Точность = 0.82, Полнота = 0.75, f1 = 0.7820\n",
      "Порог = 0.39 | Точность = 0.83, Полнота = 0.74, f1 = 0.7827\n",
      "Порог = 0.40 | Точность = 0.83, Полнота = 0.74, f1 = 0.7826\n"
     ]
    }
   ],
   "source": [
    "model = SGDC\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.3, 0.4, 0.01):\n",
    "    predicted_test = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_test, predicted_test)\n",
    "    recall = recall_score(target_test, predicted_test)\n",
    "    f1 = f1_score(target_test, predicted_test)\n",
    "    print(\"Порог = {:.2f} | Точность = {:.2f}, Полнота = {:.2f}, f1 = {:.4f}\".format(threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший f1 = 0.783, достигается при пороге = 0.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на что способна нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим корпус и для ускорения работы оставим 3000 строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"toxic_comments.csv\")\n",
    "# batch_1 = df.sample(3000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку я выбираю 3000 СЛУЧАЙНЫХ текстов из корпуса, то результат получается не вполне стабильный. А увеличить выборку я не могу из-за ограниченности русурсов. Поэтому я сохраню выборку в csv из которого она будет подтягиваться при работе проекта. А формирование выборки закомментирую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_1.to_csv('batch_1.csv',  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = pd.read_csv(\"batch_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evidently it is one rule for unfavorable accou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where am I? What happened?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E. E. Cummings \\n\\nE. E. Cummings' name should...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\n\\nYou like the article? Remember, Jehovah i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous is a hacktivist group, they have hac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>\"\\n\\n Lololol \\n\\nEvil. Haha. Well I just saw ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Edit wars and questions \\n\\nHi - you posted on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Thanks for including in the disscusion. Neutra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Is Denise Lor still alive and if so where does...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>\"\\nYour reference to a wireless modem makes it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxic\n",
       "0     Evidently it is one rule for unfavorable accou...      1\n",
       "1                            Where am I? What happened?      0\n",
       "2     E. E. Cummings \\n\\nE. E. Cummings' name should...      0\n",
       "3     \"\\n\\nYou like the article? Remember, Jehovah i...      0\n",
       "4     Anonymous is a hacktivist group, they have hac...      0\n",
       "...                                                 ...    ...\n",
       "2995  \"\\n\\n Lololol \\n\\nEvil. Haha. Well I just saw ...      0\n",
       "2996  Edit wars and questions \\n\\nHi - you posted on...      0\n",
       "2997  Thanks for including in the disscusion. Neutra...      0\n",
       "2998  Is Denise Lor still alive and if so where does...      0\n",
       "2999  \"\\nYour reference to a wireless modem makes it...      0\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2681\n",
       "1     319\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Те же 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим предварительно обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "#Для получения полноценной BERT можно раскоментировать следующую строку:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "#Предварительно обученная модель токенизатор\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем токенизацию каждого выражения в нашей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized = batch_1[\"text\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрм на токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 15329, 2009, 2003, 2028, 3627, 2005, 489...\n",
       "1       [101, 2073, 2572, 1045, 1029, 2054, 3047, 1029...\n",
       "2       [101, 1041, 1012, 1041, 1012, 20750, 1041, 101...\n",
       "3       [101, 1000, 2017, 2066, 1996, 3720, 1029, 3342...\n",
       "4       [101, 10812, 2003, 1037, 20578, 29068, 2923, 2...\n",
       "                              ...                        \n",
       "2995    [101, 1000, 8840, 4135, 4135, 2140, 4763, 1012...\n",
       "2996    [101, 10086, 5233, 1998, 3980, 7632, 1011, 201...\n",
       "2997    [101, 4283, 2005, 2164, 1999, 1996, 4487, 4757...\n",
       "2998    [101, 2003, 15339, 8840, 2099, 2145, 4142, 199...\n",
       "2999    [101, 1000, 2115, 4431, 2000, 1037, 9949, 5549...\n",
       "Name: text, Length: 3000, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После токенизации tokenized представляет собой список предложений - каждое предложение представлено в виде списка токенов. Мы хотим, чтобы Берт обрабатывал наши примеры все сразу (как один пакет). Просто так будет быстрее. По этой причине нам нужно заполнить все списки до одного размера, чтобы мы могли представить входные данные как один 2-d массив, а не список списков (разной длины)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Массив имеет размер (3000, 1599)\n"
     ]
    }
   ],
   "source": [
    "print(\"Массив имеет размер\", np.array(padded).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из опыта мы знаем, что обрабатывать вектора длинной более 50 сложно и ядро умирает. Поэтому ограничим этот размер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = padded[:, :50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новый размер массива (3000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Новый размер массива\", np.array(padded).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поясним модели, что нули не несут значимой информации. Это нужно для компоненты модели, которая называется «внимание» (англ. attention). Отбросим эти токены и «создадим маску» для действительно важных токенов, то есть укажем нулевые и не нулевые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 50)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём преобразование текстов в эмбеддинги. Это может занять несколько минут, поэтому подключим библиотеку tqdm (араб. taqadum, تقدّم, «прогресс»). Она нужна, чтобы наглядно показать индикатор прогресса. В Jupyter применим функцию notebook() из этой библиотеки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эмбеддинги модель BERT создаёт батчами. Чтобы хватило оперативной памяти, сделаем размер батча небольшим. Мы срежем только ту часть выходных данных, которая нам нужна. Это выход, соответствующий первому знаку каждого предложения. Способ, которым Берт делает классификацию предложений, заключается в том, что он добавляет маркер под названием [CLS] (для классификации) в начале каждого предложения. Вывод, соответствующий этому маркеру, можно рассматривать как вложение для всего предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4ae3a034274a1c904d0ae5c44a4efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import notebook\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём все эмбеддинги в матрицу признаков вызовом функции concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = batch_1[\"toxic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем обучающую и тестовую выбоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результаты работы логистической регрессии на дефолтных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.574468085106383\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(features_train, target_train)\n",
    "y_predict = lr_clf.predict(features_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "print(f1_score(target_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на f1 при изменении порога классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.35 | Точность = 0.55, Полнота = 0.59, f1 = 0.5714\n",
      "Порог = 0.36 | Точность = 0.54, Полнота = 0.57, f1 = 0.5586\n",
      "Порог = 0.37 | Точность = 0.54, Полнота = 0.57, f1 = 0.5586\n",
      "Порог = 0.38 | Точность = 0.58, Полнота = 0.57, f1 = 0.5794\n",
      "Порог = 0.39 | Точность = 0.57, Полнота = 0.54, f1 = 0.5524\n",
      "Порог = 0.40 | Точность = 0.60, Полнота = 0.52, f1 = 0.5545\n",
      "Порог = 0.41 | Точность = 0.60, Полнота = 0.52, f1 = 0.5545\n",
      "Порог = 0.42 | Точность = 0.60, Полнота = 0.52, f1 = 0.5545\n",
      "Порог = 0.43 | Точность = 0.61, Полнота = 0.52, f1 = 0.5600\n",
      "Порог = 0.44 | Точность = 0.61, Полнота = 0.52, f1 = 0.5600\n",
      "Порог = 0.45 | Точность = 0.63, Полнота = 0.50, f1 = 0.5567\n"
     ]
    }
   ],
   "source": [
    "model = lr_clf\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.35, 0.45, 0.01):\n",
    "    predicted_test = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_test, predicted_test)\n",
    "    recall = recall_score(target_test, predicted_test)\n",
    "    f1 = f1_score(target_test, predicted_test)\n",
    "    print(\"Порог = {:.2f} | Точность = {:.2f}, Полнота = {:.2f}, f1 = {:.4f}\".format(threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший f1 достигается при пороге = 0.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить результат работы модели с помощью подбора параметров средствами библиотеки hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выполняется долго, поэтому я его закомментировал, а результат перенес в словарь best и в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 50/50 [05:47<00:00,  6.94s/trial, best loss: 0.17363525730180807]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import Trials\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin\n",
    "\n",
    "N_FOLDS = 10\n",
    "MAX_EVALS = 50\n",
    "\n",
    "\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Logistic Regression Hyperparameter Tuning\"\"\"\n",
    "\n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evaluate based on ROC AUC\n",
    "\n",
    "    clf = LogisticRegression(**params, random_state=12345, verbose =0)\n",
    "    scores = cross_val_score(clf, features_train, target_train, cv=3, scoring='f1_macro')\n",
    "\n",
    "    # Extract the best score\n",
    "    best_score = max(scores)\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, \"balanced\"]),\n",
    "    'penalty': hp.choice('penalty', [\"l1\", \"l2\"]),\n",
    "    'warm_start' : hp.choice('warm_start', [True, False]),\n",
    "    'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
    "    'C' : hp.uniform('C', 0.05, 3),\n",
    "    'max_iter' : hp.choice('max_iter', range(5, 1000))\n",
    "}\n",
    "\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = bayes_trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.3161314187759485,\n",
       " 'class_weight': 0,\n",
       " 'max_iter': 720,\n",
       " 'penalty': 0,\n",
       " 'tol': 2.215304976357311e-05,\n",
       " 'warm_start': 1}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с лучшими параметрамии получим предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score тест 0.553191489361702\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=12345, C = 1.3161314187759485, penalty = \"l1\", max_iter = 720, tol = 2.215304976357311e-05, warm_start = True, class_weight = None)\n",
    "LR.fit(features_train, target_train)\n",
    "\n",
    "y_predict_test = LR.predict(features_test)\n",
    "\n",
    "print(\"f1_score тест\", f1_score(target_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на f1 при измеении порога классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.35 | Точность = 0.54, Полнота = 0.57, f1 = 0.5586\n",
      "Порог = 0.36 | Точность = 0.55, Полнота = 0.56, f1 = 0.5505\n",
      "Порог = 0.37 | Точность = 0.55, Полнота = 0.56, f1 = 0.5505\n",
      "Порог = 0.38 | Точность = 0.57, Полнота = 0.56, f1 = 0.5607\n",
      "Порог = 0.39 | Точность = 0.57, Полнота = 0.56, f1 = 0.5607\n",
      "Порог = 0.40 | Точность = 0.56, Полнота = 0.54, f1 = 0.5472\n",
      "Порог = 0.41 | Точность = 0.55, Полнота = 0.52, f1 = 0.5333\n",
      "Порог = 0.42 | Точность = 0.60, Полнота = 0.52, f1 = 0.5545\n",
      "Порог = 0.43 | Точность = 0.61, Полнота = 0.52, f1 = 0.5600\n",
      "Порог = 0.44 | Точность = 0.62, Полнота = 0.52, f1 = 0.5657\n",
      "Порог = 0.45 | Точность = 0.64, Полнота = 0.52, f1 = 0.5714\n",
      "Порог = 0.46 | Точность = 0.64, Полнота = 0.52, f1 = 0.5714\n",
      "Порог = 0.47 | Точность = 0.63, Полнота = 0.50, f1 = 0.5567\n",
      "Порог = 0.48 | Точность = 0.62, Полнота = 0.48, f1 = 0.5417\n",
      "Порог = 0.49 | Точность = 0.63, Полнота = 0.48, f1 = 0.5474\n",
      "Порог = 0.50 | Точность = 0.65, Полнота = 0.48, f1 = 0.5532\n",
      "Порог = 0.51 | Точность = 0.65, Полнота = 0.48, f1 = 0.5532\n",
      "Порог = 0.52 | Точность = 0.67, Полнота = 0.48, f1 = 0.5591\n",
      "Порог = 0.53 | Точность = 0.68, Полнота = 0.48, f1 = 0.5652\n",
      "Порог = 0.54 | Точность = 0.68, Полнота = 0.48, f1 = 0.5652\n",
      "Порог = 0.55 | Точность = 0.68, Полнота = 0.48, f1 = 0.5652\n"
     ]
    }
   ],
   "source": [
    "model = LR\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.35, 0.55, 0.01):\n",
    "    predicted_test = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_test, predicted_test)\n",
    "    recall = recall_score(target_test, predicted_test)\n",
    "    f1 = f1_score(target_test, predicted_test)\n",
    "    print(\"Порог = {:.2f} | Точность = {:.2f}, Полнота = {:.2f}, f1 = {:.4f}\".format(threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший f1 достигается при пороге = 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как покажет сябя стахостический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
       "              random_state=12345, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDC = SGDClassifier(loss = \"log\", penalty = \"l1\", random_state=12345, alpha=0.0001)\n",
    "SGDC.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score тест 0.5607476635514018\n"
     ]
    }
   ],
   "source": [
    "y_predict_test = SGDC.predict(features_test)\n",
    "\n",
    "print(\"f1_score тест\", f1_score(target_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.65 | Точность = 0.19, Полнота = 0.83, f1 = 0.3030\n",
      "Порог = 0.66 | Точность = 0.19, Полнота = 0.83, f1 = 0.3030\n",
      "Порог = 0.67 | Точность = 0.19, Полнота = 0.83, f1 = 0.3030\n",
      "Порог = 0.68 | Точность = 0.19, Полнота = 0.83, f1 = 0.3030\n",
      "Порог = 0.69 | Точность = 0.19, Полнота = 0.83, f1 = 0.3041\n",
      "Порог = 0.70 | Точность = 0.19, Полнота = 0.83, f1 = 0.3041\n",
      "Порог = 0.71 | Точность = 0.19, Полнота = 0.83, f1 = 0.3041\n",
      "Порог = 0.72 | Точность = 0.19, Полнота = 0.83, f1 = 0.3041\n",
      "Порог = 0.73 | Точность = 0.19, Полнота = 0.83, f1 = 0.3041\n",
      "Порог = 0.74 | Точность = 0.19, Полнота = 0.83, f1 = 0.3041\n",
      "Порог = 0.75 | Точность = 0.19, Полнота = 0.83, f1 = 0.3041\n",
      "Порог = 0.76 | Точность = 0.18, Полнота = 0.81, f1 = 0.2983\n",
      "Порог = 0.77 | Точность = 0.18, Полнота = 0.81, f1 = 0.2983\n",
      "Порог = 0.78 | Точность = 0.18, Полнота = 0.81, f1 = 0.2983\n",
      "Порог = 0.79 | Точность = 0.18, Полнота = 0.81, f1 = 0.2983\n",
      "Порог = 0.80 | Точность = 0.18, Полнота = 0.81, f1 = 0.2983\n",
      "Порог = 0.81 | Точность = 0.18, Полнота = 0.81, f1 = 0.2983\n",
      "Порог = 0.82 | Точность = 0.18, Полнота = 0.81, f1 = 0.2983\n",
      "Порог = 0.83 | Точность = 0.18, Полнота = 0.81, f1 = 0.2993\n",
      "Порог = 0.84 | Точность = 0.18, Полнота = 0.81, f1 = 0.2993\n"
     ]
    }
   ],
   "source": [
    "model = SGDC\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.65, 0.85, 0.01):\n",
    "    predicted_test = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_test, predicted_test)\n",
    "    recall = recall_score(target_test, predicted_test)\n",
    "    f1 = f1_score(target_test, predicted_test)\n",
    "    print(\"Порог = {:.2f} | Точность = {:.2f}, Полнота = {:.2f}, f1 = {:.4f}\".format(threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший f1 при пороге = 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбеем лучшие параметры с помощью hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 50/50 [02:29<00:00,  2.99s/trial, best loss: 0.17645222212068612]\n"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 10\n",
    "MAX_EVALS = 50\n",
    "\n",
    "\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Logistic Regression Hyperparameter Tuning\"\"\"\n",
    "\n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evaluate based on ROC AUC\n",
    "\n",
    "    clf = SGDClassifier(**params, loss = \"log\", random_state=12345, verbose = 0)\n",
    "    scores = cross_val_score(clf, features_train, target_train, cv=3, scoring='f1_macro')\n",
    "\n",
    "    # Extract the best score\n",
    "    best_score = max(scores)\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, \"balanced\"]),\n",
    "    'penalty': hp.choice('penalty', [\"l1\", \"l2\"]),\n",
    "    'warm_start' : hp.choice('warm_start', [True, False]),\n",
    "    'fit_intercept' : hp.choice('fit_intercept', [True, False]),\n",
    "    'alpha' : hp.uniform('alpha', 0.0000001, 0.0001),\n",
    "    'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
    "    'max_iter' : hp.choice('max_iter', range(5, 1000))\n",
    "}\n",
    "\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = bayes_trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 7.637102721429022e-05,\n",
       " 'class_weight': 1,\n",
       " 'fit_intercept': 1,\n",
       " 'max_iter': 339,\n",
       " 'penalty': 1,\n",
       " 'tol': 6.91788699363432e-05,\n",
       " 'warm_start': 1}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с лучшими параметрами и получим предстказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score тест 0.5\n"
     ]
    }
   ],
   "source": [
    "SGDC = SGDClassifier(fit_intercept = False, alpha = 3.3211820238627403e-05, loss = \"log\", random_state=12345, penalty = \"l2\", max_iter = 339, tol = 6.91788699363432e-05, warm_start = False, class_weight = \"balanced\")\n",
    "SGDC.fit(features_train, target_train)\n",
    "\n",
    "y_predict_test = SGDC.predict(features_test)\n",
    "\n",
    "print(\"f1_score тест\", f1_score(target_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем лучший порог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.10 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.11 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.12 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.13 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.14 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.15 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.16 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.17 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.18 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.19 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.20 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.21 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.22 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.23 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.24 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.25 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.26 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.27 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.28 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n",
      "Порог = 0.29 | Точность = 0.44, Полнота = 0.63, f1 = 0.5152\n"
     ]
    }
   ],
   "source": [
    "model = SGDC\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.1, 0.3, 0.01):\n",
    "    predicted_test = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_test, predicted_test)\n",
    "    recall = recall_score(target_test, predicted_test)\n",
    "    f1 = f1_score(target_test, predicted_test)\n",
    "    print(\"Порог = {:.2f} | Точность = {:.2f}, Полнота = {:.2f}, f1 = {:.4f}\".format(threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший f1 при пороге = 0.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. В процессе работы была проведена очистка и лемматизация данных\n",
    "2. Далее данные были подготовлены для обучения следующими методами:\n",
    "   * TF-IDF\n",
    "   * предобработка моделью BERT (упрощенным вариантом - DistilBert)\n",
    "3. В проекте были использованы модели Логистическая регрессия и Стохастический градиентный спуск\n",
    "4. Параметры для моделей подбирались с помощью библиотеки Hyperopt\n",
    "5. Показатель дополнительно f1 улучшался с помощью изменения порога классификации\n",
    "5. Наилучшие результаты f1 = 0.7842 были получены на модели логистической регрессии с параметрами определенными с помощью hyperopt и порогом классификации 0.4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
